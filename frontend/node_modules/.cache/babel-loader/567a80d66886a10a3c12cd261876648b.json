{"ast":null,"code":"var _jsxFileName = \"/Users/codyum/Desktop/Github/h4tp/src/App.js\";\nimport React from 'react';\nimport logo from \"./logo.svg\";\nimport './App.css';\n\nconst recorder = require('node-record-lpcm16');\n\nconst speech = require('@google-cloud/speech');\n\nconst client = new speech.SpeechClient();\nconst encoding = 'LINEAR16';\nconst sampleRateHertz = 16000;\nconst languageCode = 'en-US';\n\nfunction App() {\n  const request = {\n    config: {\n      encoding: encoding,\n      sampleRateHertz: sampleRateHertz,\n      languageCode: languageCode\n    },\n    interimResults: false // If you want interim results, set this to true\n\n  }; // Create a recognize stream\n\n  const recognizeStream = client.streamingRecognize(request).on('error', console.error).on('data', data => process.stdout.write(data.results[0] && data.results[0].alternatives[0] ? `Transcription: ${data.results[0].alternatives[0].transcript}\\n` : '\\n\\nReached transcription time limit, press Ctrl+C\\n')); // Start recording and send the microphone input to the Speech API.\n  // Ensure SoX is installed, see https://www.npmjs.com/package/node-record-lpcm16#dependencies\n\n  recorder.record({\n    sampleRateHertz: sampleRateHertz,\n    threshold: 0,\n    // Other options, see https://www.npmjs.com/package/node-record-lpcm16#options\n    verbose: false,\n    recordProgram: 'rec',\n    // Try also \"arecord\" or \"sox\"\n    silence: '10.0'\n  }).stream().on('error', console.error).pipe(recognizeStream);\n  console.log('Listening, press Ctrl+C to stop.');\n  return /*#__PURE__*/React.createElement(\"div\", {\n    className: \"App\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 53,\n      columnNumber: 5\n    }\n  }, /*#__PURE__*/React.createElement(\"header\", {\n    className: \"App-header\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 54,\n      columnNumber: 7\n    }\n  }, /*#__PURE__*/React.createElement(\"img\", {\n    src: logo,\n    className: \"App-logo\",\n    alt: \"logo\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 55,\n      columnNumber: 9\n    }\n  }), /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 56,\n      columnNumber: 9\n    }\n  }, \"Edit \", /*#__PURE__*/React.createElement(\"code\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 57,\n      columnNumber: 16\n    }\n  }, \"src/App.js\"), \" and save to reload.\"), /*#__PURE__*/React.createElement(\"a\", {\n    className: \"App-link\",\n    href: \"https://reactjs.org\",\n    target: \"_blank\",\n    rel: \"noopener noreferrer\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 59,\n      columnNumber: 9\n    }\n  }, \"Learn React\")));\n}\n\nexport default App;","map":{"version":3,"sources":["/Users/codyum/Desktop/Github/h4tp/src/App.js"],"names":["React","recorder","require","speech","client","SpeechClient","encoding","sampleRateHertz","languageCode","App","request","config","interimResults","recognizeStream","streamingRecognize","on","console","error","data","process","stdout","write","results","alternatives","transcript","record","threshold","verbose","recordProgram","silence","stream","pipe","log","logo"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB;;AAEA,OAAO,WAAP;;AACA,MAAMC,QAAQ,GAAGC,OAAO,CAAC,oBAAD,CAAxB;;AACA,MAAMC,MAAM,GAAGD,OAAO,CAAC,sBAAD,CAAtB;;AACA,MAAME,MAAM,GAAG,IAAID,MAAM,CAACE,YAAX,EAAf;AAEA,MAAMC,QAAQ,GAAG,UAAjB;AACA,MAAMC,eAAe,GAAG,KAAxB;AACA,MAAMC,YAAY,GAAG,OAArB;;AAEA,SAASC,GAAT,GAAe;AACb,QAAMC,OAAO,GAAG;AACdC,IAAAA,MAAM,EAAE;AACNL,MAAAA,QAAQ,EAAEA,QADJ;AAENC,MAAAA,eAAe,EAAEA,eAFX;AAGNC,MAAAA,YAAY,EAAEA;AAHR,KADM;AAMdI,IAAAA,cAAc,EAAE,KANF,CAMS;;AANT,GAAhB,CADa,CAUb;;AACA,QAAMC,eAAe,GAAGT,MAAM,CAC3BU,kBADqB,CACFJ,OADE,EAErBK,EAFqB,CAElB,OAFkB,EAETC,OAAO,CAACC,KAFC,EAGrBF,EAHqB,CAGlB,MAHkB,EAGVG,IAAI,IACdC,OAAO,CAACC,MAAR,CAAeC,KAAf,CACEH,IAAI,CAACI,OAAL,CAAa,CAAb,KAAmBJ,IAAI,CAACI,OAAL,CAAa,CAAb,EAAgBC,YAAhB,CAA6B,CAA7B,CAAnB,GACK,kBAAiBL,IAAI,CAACI,OAAL,CAAa,CAAb,EAAgBC,YAAhB,CAA6B,CAA7B,EAAgCC,UAAW,IADjE,GAEI,sDAHN,CAJoB,CAAxB,CAXa,CAsBb;AACA;;AACAvB,EAAAA,QAAQ,CACLwB,MADH,CACU;AACNlB,IAAAA,eAAe,EAAEA,eADX;AAENmB,IAAAA,SAAS,EAAE,CAFL;AAGN;AACAC,IAAAA,OAAO,EAAE,KAJH;AAKNC,IAAAA,aAAa,EAAE,KALT;AAKgB;AACtBC,IAAAA,OAAO,EAAE;AANH,GADV,EASGC,MATH,GAUGf,EAVH,CAUM,OAVN,EAUeC,OAAO,CAACC,KAVvB,EAWGc,IAXH,CAWQlB,eAXR;AAaAG,EAAAA,OAAO,CAACgB,GAAR,CAAY,kCAAZ;AAGA,sBACE;AAAK,IAAA,SAAS,EAAC,KAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACE;AAAQ,IAAA,SAAS,EAAC,YAAlB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACE;AAAK,IAAA,GAAG,EAAEC,IAAV;AAAgB,IAAA,SAAS,EAAC,UAA1B;AAAqC,IAAA,GAAG,EAAC,MAAzC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,eAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BACO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBADP,yBAFF,eAKE;AACE,IAAA,SAAS,EAAC,UADZ;AAEE,IAAA,IAAI,EAAC,qBAFP;AAGE,IAAA,MAAM,EAAC,QAHT;AAIE,IAAA,GAAG,EAAC,qBAJN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBALF,CADF,CADF;AAkBD;;AAED,eAAexB,GAAf","sourcesContent":["import React from 'react';\nimport logo from './logo.svg';\nimport './App.css';\nconst recorder = require('node-record-lpcm16');\nconst speech = require('@google-cloud/speech');\nconst client = new speech.SpeechClient();\n\nconst encoding = 'LINEAR16';\nconst sampleRateHertz = 16000;\nconst languageCode = 'en-US';\n\nfunction App() {\n  const request = {\n    config: {\n      encoding: encoding,\n      sampleRateHertz: sampleRateHertz,\n      languageCode: languageCode,\n    },\n    interimResults: false, // If you want interim results, set this to true\n  };\n  \n  // Create a recognize stream\n  const recognizeStream = client\n    .streamingRecognize(request)\n    .on('error', console.error)\n    .on('data', data =>\n      process.stdout.write(\n        data.results[0] && data.results[0].alternatives[0]\n          ? `Transcription: ${data.results[0].alternatives[0].transcript}\\n`\n          : '\\n\\nReached transcription time limit, press Ctrl+C\\n'\n      )\n    );\n  \n  // Start recording and send the microphone input to the Speech API.\n  // Ensure SoX is installed, see https://www.npmjs.com/package/node-record-lpcm16#dependencies\n  recorder\n    .record({\n      sampleRateHertz: sampleRateHertz,\n      threshold: 0,\n      // Other options, see https://www.npmjs.com/package/node-record-lpcm16#options\n      verbose: false,\n      recordProgram: 'rec', // Try also \"arecord\" or \"sox\"\n      silence: '10.0',\n    })\n    .stream()\n    .on('error', console.error)\n    .pipe(recognizeStream);\n  \n  console.log('Listening, press Ctrl+C to stop.');\n\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <img src={logo} className=\"App-logo\" alt=\"logo\" />\n        <p>\n          Edit <code>src/App.js</code> and save to reload.\n        </p>\n        <a\n          className=\"App-link\"\n          href=\"https://reactjs.org\"\n          target=\"_blank\"\n          rel=\"noopener noreferrer\"\n        >\n          Learn React\n        </a>\n      </header>\n    </div>\n  );\n}\n\nexport default App;\n"]},"metadata":{},"sourceType":"module"}