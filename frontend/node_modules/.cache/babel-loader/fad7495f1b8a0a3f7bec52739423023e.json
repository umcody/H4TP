{"ast":null,"code":"var _jsxFileName = \"/Users/codyum/Desktop/Github/h4tp/src/components/test.js\";\nimport React from 'react';\nimport { Link } from 'react-router-dom';\n\nconst recorder = require('node-record-lpcm16');\n\nconst speech = require('@google-cloud/speech');\n\nconst db = require('../firebase/config').db;\n\nconst encoding = 'LINEAR16';\nconst sampleRateHertz = 16000;\nconst languageCode = 'en-US';\n\nconst auth = require('google-auth-library');\n\nconst oauth2client = new auth.OAuth2Client(client_id, client_secret, callback_uri);\nconst authUrl = oauth2client.generateAuthUrl({\n  access_type: 'offline',\n  scope: [// scopes for Dialogflow\n  'https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/dialogflow']\n});\nconst request = {\n  config: {\n    encoding: encoding,\n    sampleRateHertz: sampleRateHertz,\n    languageCode: languageCode\n  },\n  interimResults: false // If you want interim results, set this to true\n\n};\n\nasync function Write() {\n  const tokenResponse = await oauth2client.getToken(code);\n  oauth2client.setCredentials(tokenResponse.tokens);\n  const client = new speech.SpeechClient({\n    auth: oauth2client\n  });\n\n  const writeData = async transcript => {\n    try {\n      await db.ref().push({\n        content: transcript // lorem2 should be replaced with text from Google Speech2Text API\n\n      });\n    } catch (e) {\n      console.log(e);\n    }\n  }; // Create a recognize stream\n\n\n  const recognizeStream = client.streamingRecognize(request).on('error', console.error).on('data', data => {\n    process.stdout.write(data.results[0] && data.results[0].alternatives[0] ? `Transcription: ${data.results[0].alternatives[0].transcript}\\n` : '\\n\\nReached transcription time limit, press Ctrl+C\\n'); //*******/\n\n    return console.log(data.results[0].alternatives[0].transcript);\n  }); // Start recording and send the microphone input to the Speech API.\n  // Ensure SoX is installed, see https://www.npmjs.com/package/node-record-lpcm16#dependencies\n\n  recorder.record({\n    sampleRateHertz: sampleRateHertz,\n    threshold: 0,\n    // Other options, see https://www.npmjs.com/package/node-record-lpcm16#options\n    verbose: false,\n    recordProgram: 'rec',\n    // Try also \"arecord\" or \"sox\"\n    silence: '10.0'\n  }).stream().on('error', console.error).pipe(recognizeStream);\n  return /*#__PURE__*/React.createElement(\"div\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 78,\n      columnNumber: 5\n    }\n  });\n}\n\nexport default Write;","map":{"version":3,"sources":["/Users/codyum/Desktop/Github/h4tp/src/components/test.js"],"names":["React","Link","recorder","require","speech","db","encoding","sampleRateHertz","languageCode","auth","oauth2client","OAuth2Client","client_id","client_secret","callback_uri","authUrl","generateAuthUrl","access_type","scope","request","config","interimResults","Write","tokenResponse","getToken","code","setCredentials","tokens","client","SpeechClient","writeData","transcript","ref","push","content","e","console","log","recognizeStream","streamingRecognize","on","error","data","process","stdout","write","results","alternatives","record","threshold","verbose","recordProgram","silence","stream","pipe"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB;AACA,SAASC,IAAT,QAAqB,kBAArB;;AACA,MAAMC,QAAQ,GAAGC,OAAO,CAAC,oBAAD,CAAxB;;AACA,MAAMC,MAAM,GAAGD,OAAO,CAAC,sBAAD,CAAtB;;AACA,MAAME,EAAE,GAAGF,OAAO,CAAC,oBAAD,CAAP,CAA8BE,EAAzC;;AACA,MAAMC,QAAQ,GAAG,UAAjB;AACA,MAAMC,eAAe,GAAG,KAAxB;AACA,MAAMC,YAAY,GAAG,OAArB;;AAEA,MAAMC,IAAI,GAAGN,OAAO,CAAC,qBAAD,CAApB;;AACA,MAAMO,YAAY,GAAG,IAAID,IAAI,CAACE,YAAT,CAAsBC,SAAtB,EAAiCC,aAAjC,EAAgDC,YAAhD,CAArB;AACA,MAAMC,OAAO,GAAGL,YAAY,CAACM,eAAb,CAA6B;AAC3CC,EAAAA,WAAW,EAAE,SAD8B;AAE3CC,EAAAA,KAAK,EAAE,CAAK;AACV,kDADK,EAEL,4CAFK;AAFoC,CAA7B,CAAhB;AAQA,MAAMC,OAAO,GAAG;AACdC,EAAAA,MAAM,EAAE;AACNd,IAAAA,QAAQ,EAAEA,QADJ;AAENC,IAAAA,eAAe,EAAEA,eAFX;AAGNC,IAAAA,YAAY,EAAEA;AAHR,GADM;AAMda,EAAAA,cAAc,EAAE,KANF,CAMS;;AANT,CAAhB;;AASA,eAAeC,KAAf,GAAuB;AAErB,QAAMC,aAAa,GAAG,MAAMb,YAAY,CAACc,QAAb,CAAsBC,IAAtB,CAA5B;AACAf,EAAAA,YAAY,CAACgB,cAAb,CAA4BH,aAAa,CAACI,MAA1C;AACA,QAAMC,MAAM,GAAG,IAAIxB,MAAM,CAACyB,YAAX,CAAwB;AAAEpB,IAAAA,IAAI,EAAEC;AAAR,GAAxB,CAAf;;AAGA,QAAMoB,SAAS,GAAG,MAAOC,UAAP,IAAsB;AACtC,QAAI;AACF,YAAM1B,EAAE,CAAC2B,GAAH,GAASC,IAAT,CAAc;AAClBC,QAAAA,OAAO,EAAEH,UADS,CACE;;AADF,OAAd,CAAN;AAGD,KAJD,CAIE,OAAOI,CAAP,EAAU;AACVC,MAAAA,OAAO,CAACC,GAAR,CAAYF,CAAZ;AACD;AACF,GARD,CAPqB,CAiBrB;;;AACA,QAAMG,eAAe,GAAGV,MAAM,CAC3BW,kBADqB,CACFpB,OADE,EAErBqB,EAFqB,CAElB,OAFkB,EAETJ,OAAO,CAACK,KAFC,EAGrBD,EAHqB,CAGlB,MAHkB,EAGVE,IAAI,IAAI;AAClBC,IAAAA,OAAO,CAACC,MAAR,CAAeC,KAAf,CACEH,IAAI,CAACI,OAAL,CAAa,CAAb,KAAmBJ,IAAI,CAACI,OAAL,CAAa,CAAb,EAAgBC,YAAhB,CAA6B,CAA7B,CAAnB,GACK,kBAAiBL,IAAI,CAACI,OAAL,CAAa,CAAb,EAAgBC,YAAhB,CAA6B,CAA7B,EAAgChB,UAAW,IADjE,GAEI,sDAHN,EADkB,CAMlB;;AACA,WAAOK,OAAO,CAACC,GAAR,CAAYK,IAAI,CAACI,OAAL,CAAa,CAAb,EAAgBC,YAAhB,CAA6B,CAA7B,EAAgChB,UAA5C,CAAP;AACD,GAXqB,CAAxB,CAlBqB,CAgCrB;AACA;;AACA7B,EAAAA,QAAQ,CACL8C,MADH,CACU;AACNzC,IAAAA,eAAe,EAAEA,eADX;AAEN0C,IAAAA,SAAS,EAAE,CAFL;AAGN;AACAC,IAAAA,OAAO,EAAE,KAJH;AAKNC,IAAAA,aAAa,EAAE,KALT;AAKgB;AACtBC,IAAAA,OAAO,EAAE;AANH,GADV,EASGC,MATH,GAUGb,EAVH,CAUM,OAVN,EAUeJ,OAAO,CAACK,KAVvB,EAWGa,IAXH,CAWQhB,eAXR;AAcA,sBACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF;AAID;;AAED,eAAehB,KAAf","sourcesContent":["import React from 'react';\nimport { Link } from 'react-router-dom';\nconst recorder = require('node-record-lpcm16');\nconst speech = require('@google-cloud/speech');\nconst db = require('../firebase/config').db;\nconst encoding = 'LINEAR16';\nconst sampleRateHertz = 16000;\nconst languageCode = 'en-US';\n\nconst auth = require('google-auth-library');\nconst oauth2client = new auth.OAuth2Client(client_id, client_secret, callback_uri);\nconst authUrl = oauth2client.generateAuthUrl({\n  access_type: 'offline',\n  scope: [    // scopes for Dialogflow\n    'https://www.googleapis.com/auth/cloud-platform',\n    'https://www.googleapis.com/auth/dialogflow'\n  ]\n});\n\nconst request = {\n  config: {\n    encoding: encoding,\n    sampleRateHertz: sampleRateHertz,\n    languageCode: languageCode,\n  },\n  interimResults: false, // If you want interim results, set this to true\n};\n\nasync function Write() {\n\n  const tokenResponse = await oauth2client.getToken(code);\n  oauth2client.setCredentials(tokenResponse.tokens);\n  const client = new speech.SpeechClient({ auth: oauth2client });\n\n\n  const writeData = async (transcript) => {\n    try {\n      await db.ref().push({\n        content: transcript // lorem2 should be replaced with text from Google Speech2Text API\n      });\n    } catch (e) {\n      console.log(e);\n    }\n  };\n\n  // Create a recognize stream\n  const recognizeStream = client\n    .streamingRecognize(request)\n    .on('error', console.error)\n    .on('data', data => {\n      process.stdout.write(\n        data.results[0] && data.results[0].alternatives[0]\n          ? `Transcription: ${data.results[0].alternatives[0].transcript}\\n`\n          : '\\n\\nReached transcription time limit, press Ctrl+C\\n'\n      );\n      //*******/\n      return console.log(data.results[0].alternatives[0].transcript);\n    }\n    );\n\n  // Start recording and send the microphone input to the Speech API.\n  // Ensure SoX is installed, see https://www.npmjs.com/package/node-record-lpcm16#dependencies\n  recorder\n    .record({\n      sampleRateHertz: sampleRateHertz,\n      threshold: 0,\n      // Other options, see https://www.npmjs.com/package/node-record-lpcm16#options\n      verbose: false,\n      recordProgram: 'rec', // Try also \"arecord\" or \"sox\"\n      silence: '10.0',\n    })\n    .stream()\n    .on('error', console.error)\n    .pipe(recognizeStream);\n\n\n  return (\n    <div>\n    </div>\n  );\n}\n\nexport default Write;\n"]},"metadata":{},"sourceType":"module"}