{"ast":null,"code":"\"use strict\";\n/*\n * Copyright 2017 Google Inc. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.ImprovedStreamingClient = void 0;\n\nconst common = require(\"@google-cloud/common\");\n\nconst pumpify = require(\"pumpify\");\n\nconst streamEvents = require(\"stream-events\");\n\nconst stream_1 = require(\"stream\");\n\nclass ImprovedStreamingClient {\n  /**\n   * Performs bidirectional streaming speech recognition: receive results while\n   * sending audio. This method is only available via the gRPC API (not REST).\n   *\n   * @param {object} config The configuration for the stream. This is\n   *     appropriately wrapped and sent as the first argument. It should be an\n   *     object conforming to the [StreamingRecognitionConfig]{@link StreamingRecognitionConfig}\n   *     structure.\n   * @param {object} [options] Optional parameters. You can override the default\n   *     settings for this call, e.g, timeout, retries, paginations, etc. See\n   *     [gax.CallOptions]{@link https://googleapis.github.io/gax-nodejs/global.html#CallOptions}\n   *     for the details.\n   * @returns {stream} An object stream which is both readable and writable. It\n   *     accepts raw audio for the `write()` method, and will emit objects\n   *     representing [StreamingRecognizeResponse]{@link StreamingRecognizeResponse}\n   *     on the 'data' event asynchronously.\n   *\n   * @example\n   * const speech = require('@google-cloud/speech');\n   * const client = new speech.SpeechClient();\n   *\n   * const stream = client.streamingRecognize({\n   *   config: {\n   *     encoding: 'LINEAR16',\n   *     languageCode: 'en-us',\n   *     sampleRateHertz: 44100,\n   *   },\n   * }).on('data', function(response) {\n   *   // doThingsWith(response);\n   * });\n   * const request = {};\n   * // Write request objects.\n   * stream.write(request);\n   */\n  streamingRecognize(streamingConfig, options) {\n    options = options || {};\n    streamingConfig = streamingConfig || {}; // Format the audio content as input request for pipeline\n\n    const recognizeStream = streamEvents(new pumpify.obj()); // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n    const requestStream = this._streamingRecognize(options).on('error', err => {\n      recognizeStream.destroy(err);\n    }).on('response', response => {\n      recognizeStream.emit('response', response);\n    }); // Attach the events to the request stream, but only do so\n    // when the first write (of data) comes in.\n    //\n    // This also means that the sending of the initial request (with the\n    // config) is delayed until we get the first burst of data.\n\n\n    recognizeStream.once('writing', () => {\n      // The first message should contain the streaming config.\n      requestStream.write({\n        streamingConfig\n      }); // Set up appropriate piping between the stream returned by\n      // the underlying API method and the one that we return.\n\n      recognizeStream.setPipeline([// Format the user's input.\n      // This entails that the user sends raw audio; it is wrapped in\n      // the appropriate request structure.\n      new stream_1.PassThrough({\n        objectMode: true,\n        transform: (audioContent, _, next) => {\n          if (audioContent !== undefined) {\n            next(undefined, {\n              audioContent\n            });\n            return;\n          }\n\n          next();\n        }\n      }), requestStream, new stream_1.PassThrough({\n        objectMode: true,\n        transform: (response, enc, next) => {\n          if (response.error) {\n            next(new common.util.ApiError(response.error));\n            return;\n          }\n\n          next(undefined, response);\n        }\n      })]);\n    });\n    return recognizeStream;\n  }\n\n}\n\nexports.ImprovedStreamingClient = ImprovedStreamingClient;","map":{"version":3,"sources":["../../src/helpers.ts"],"names":[],"mappings":";AAAA;;;;;;;;;;;;;;;;;;;;;AAgBA,MAAA,MAAA,GAAA,OAAA,CAAA,sBAAA,CAAA;;AACA,MAAA,OAAA,GAAA,OAAA,CAAA,SAAA,CAAA;;AACA,MAAA,YAAA,GAAA,OAAA,CAAA,eAAA,CAAA;;AACA,MAAA,QAAA,GAAA,OAAA,CAAA,QAAA,CAAA;;AAIA,MAAa,uBAAb,CAAoC;AAClC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkCA,EAAA,kBAAkB,CAChB,eADgB,EAIhB,OAJgB,EAIS;AAEzB,IAAA,OAAO,GAAG,OAAO,IAAI,EAArB;AACA,IAAA,eAAe,GAAG,eAAe,IAAI,EAArC,CAHyB,CAKzB;;AACA,UAAM,eAAe,GAAG,YAAY,CAAC,IAAI,OAAO,CAAC,GAAZ,EAAD,CAApC,CANyB,CAQzB;;AACA,UAAM,aAAa,GAAI,KACpB,mBADoB,CACA,OADA,EAEpB,EAFoB,CAEjB,OAFiB,EAEP,GAAD,IAAe;AAC1B,MAAA,eAAe,CAAC,OAAhB,CAAwB,GAAxB;AACD,KAJoB,EAKpB,EALoB,CAMnB,UANmB,EAQjB,QADF,IAII;AACF,MAAA,eAAe,CAAC,IAAhB,CAAqB,UAArB,EAAiC,QAAjC;AACD,KAbkB,CAAvB,CATyB,CAyBzB;AACA;AACA;AACA;AACA;;;AACA,IAAA,eAAe,CAAC,IAAhB,CAAqB,SAArB,EAAgC,MAAK;AACnC;AACA,MAAA,aAAa,CAAC,KAAd,CAAoB;AAAC,QAAA;AAAD,OAApB,EAFmC,CAInC;AACA;;AACA,MAAA,eAAe,CAAC,WAAhB,CAA4B,CAC1B;AACA;AACA;AACA,UAAI,QAAA,CAAA,WAAJ,CAAgB;AACd,QAAA,UAAU,EAAE,IADE;AAEd,QAAA,SAAS,EAAE,CAAC,YAAD,EAAe,CAAf,EAAkB,IAAlB,KAA0B;AACnC,cAAI,YAAY,KAAK,SAArB,EAAgC;AAC9B,YAAA,IAAI,CAAC,SAAD,EAAY;AAAC,cAAA;AAAD,aAAZ,CAAJ;AACA;AACD;;AACD,UAAA,IAAI;AACL;AARa,OAAhB,CAJ0B,EAc1B,aAd0B,EAe1B,IAAI,QAAA,CAAA,WAAJ,CAAgB;AACd,QAAA,UAAU,EAAE,IADE;AAEd,QAAA,SAAS,EAAE,CAAC,QAAD,EAAW,GAAX,EAAgB,IAAhB,KAAwB;AACjC,cAAI,QAAQ,CAAC,KAAb,EAAoB;AAClB,YAAA,IAAI,CAAC,IAAI,MAAM,CAAC,IAAP,CAAY,QAAhB,CAAyB,QAAQ,CAAC,KAAlC,CAAD,CAAJ;AACA;AACD;;AACD,UAAA,IAAI,CAAC,SAAD,EAAY,QAAZ,CAAJ;AACD;AARa,OAAhB,CAf0B,CAA5B;AA0BD,KAhCD;AAkCA,WAAO,eAAP;AACD;;AAxGiC;;AAApC,OAAA,CAAA,uBAAA,GAAA,uBAAA","sourceRoot":"","sourcesContent":["\"use strict\";\n/*\n * Copyright 2017 Google Inc. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ImprovedStreamingClient = void 0;\nconst common = require(\"@google-cloud/common\");\nconst pumpify = require(\"pumpify\");\nconst streamEvents = require(\"stream-events\");\nconst stream_1 = require(\"stream\");\nclass ImprovedStreamingClient {\n    /**\n     * Performs bidirectional streaming speech recognition: receive results while\n     * sending audio. This method is only available via the gRPC API (not REST).\n     *\n     * @param {object} config The configuration for the stream. This is\n     *     appropriately wrapped and sent as the first argument. It should be an\n     *     object conforming to the [StreamingRecognitionConfig]{@link StreamingRecognitionConfig}\n     *     structure.\n     * @param {object} [options] Optional parameters. You can override the default\n     *     settings for this call, e.g, timeout, retries, paginations, etc. See\n     *     [gax.CallOptions]{@link https://googleapis.github.io/gax-nodejs/global.html#CallOptions}\n     *     for the details.\n     * @returns {stream} An object stream which is both readable and writable. It\n     *     accepts raw audio for the `write()` method, and will emit objects\n     *     representing [StreamingRecognizeResponse]{@link StreamingRecognizeResponse}\n     *     on the 'data' event asynchronously.\n     *\n     * @example\n     * const speech = require('@google-cloud/speech');\n     * const client = new speech.SpeechClient();\n     *\n     * const stream = client.streamingRecognize({\n     *   config: {\n     *     encoding: 'LINEAR16',\n     *     languageCode: 'en-us',\n     *     sampleRateHertz: 44100,\n     *   },\n     * }).on('data', function(response) {\n     *   // doThingsWith(response);\n     * });\n     * const request = {};\n     * // Write request objects.\n     * stream.write(request);\n     */\n    streamingRecognize(streamingConfig, options) {\n        options = options || {};\n        streamingConfig = streamingConfig || {};\n        // Format the audio content as input request for pipeline\n        const recognizeStream = streamEvents(new pumpify.obj());\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        const requestStream = this\n            ._streamingRecognize(options)\n            .on('error', (err) => {\n            recognizeStream.destroy(err);\n        })\n            .on('response', (response) => {\n            recognizeStream.emit('response', response);\n        });\n        // Attach the events to the request stream, but only do so\n        // when the first write (of data) comes in.\n        //\n        // This also means that the sending of the initial request (with the\n        // config) is delayed until we get the first burst of data.\n        recognizeStream.once('writing', () => {\n            // The first message should contain the streaming config.\n            requestStream.write({ streamingConfig });\n            // Set up appropriate piping between the stream returned by\n            // the underlying API method and the one that we return.\n            recognizeStream.setPipeline([\n                // Format the user's input.\n                // This entails that the user sends raw audio; it is wrapped in\n                // the appropriate request structure.\n                new stream_1.PassThrough({\n                    objectMode: true,\n                    transform: (audioContent, _, next) => {\n                        if (audioContent !== undefined) {\n                            next(undefined, { audioContent });\n                            return;\n                        }\n                        next();\n                    },\n                }),\n                requestStream,\n                new stream_1.PassThrough({\n                    objectMode: true,\n                    transform: (response, enc, next) => {\n                        if (response.error) {\n                            next(new common.util.ApiError(response.error));\n                            return;\n                        }\n                        next(undefined, response);\n                    },\n                }),\n            ]);\n        });\n        return recognizeStream;\n    }\n}\nexports.ImprovedStreamingClient = ImprovedStreamingClient;\n//# sourceMappingURL=helpers.js.map"]},"metadata":{},"sourceType":"script"}